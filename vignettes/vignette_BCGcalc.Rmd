---
title: "Vignette, BCGcalc"
author: "Erik.Leppo@tetratech.com"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette, QW}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
<!-- Data is in vignettes\data folder  -->
```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```
# Purpose
The `BCGcalc` package was created to enable users to implement a model created Biological Condition Gradient and apply it to their data.

This vignette will cover the basics going from raw data to model results.

No files are exported in the examples in the vignette.  All "write" statements have been commented out.  Several different "write" functions were used.  This was intentional such that intermediate files are output at TSV (tab-separated values) files and final results are output as CSV (comma-separated values) files.  Both formats will open in Excel.

# Tasks
1. Metric calculation

2. Metric scoring (membership)

3. Level membership

4. Level assignment

5. Other

## Metric Calculation
The `BCGcalc` package includes some example that will be used in this example.

The funtion metric.values generates 160+ different metrics for multi-metric indices as well as BCG specific metrics.  All metrics are calculated and reported back to the user in a data frame.

No manipulations of the taxa are performed by this routine.  
All benthic macroinvertebrate taxa should be identified to the appropriate 
operational taxonomic unit (OTU).  
Any non-count taxa should be identified in the "Exclude" field as "TRUE". 
These taxa will be excluded from taxa richness metrics (but will count for 
all others).  Excluded taxa are ambiguous taxa (on a sample basis), i.e., 
the parent taxa when child taxa are present.  For example, the parent taxa 
Chironomidae would be xcluded when the child taxa Tanytarsini is present.  
Both would be excluded when Tanytarsus is present.
Any non-target taxa should be identified in the "NonTarget" field as "TRUE". 
Non-target taxa are those that are not part of your intended capture list; 
e.g., fish,  herps, water column taxa, or water surface taxa in a benthic sample.
The target list will vary by program.
The non-target taxa will be removed prior to any calculations.
There are a number of required fields (see below) for metric to calculation.  
If any fields are missing the user will be prompted as to which are missing 
and if the user wants to continue or quit.  If the user continues the missing 
fields will be added but will be filled with zero or NA (as appropriate).  
Any metrics based on the missing fields will not be valid.

Required Fields:

* SAMPLEID (character or number, must be unique)

* TAXAID (character or number, must be unique)

* N_TAXA

* EXCLUDE (valid values are TRUE and FALSE)

* INDEX_NAME

* SITE_TYPE (BCG or MMI site category; e.g., for BCG PacNW valid values are "hi" or "lo")

* NONTARGET (valid values are TRUE and FALSE)

* PHYLUM, SUBPHYLUM, CLASS, ORDER, FAMILY, SUBFAMILY, TRIBE, GENUS

* FFG, HABIT, LIFE_CYCLE, TOLVAL, BCG_ATTR, THERMAL_INDICATOR

Valid values for FFG: CG, CF, PR, SC, SH

Valid values for HABIT: BU, CB, CN, SP, SW

Valid values for LIFE_CYCLE: UNI, SEMI, MULTI

Valid values for THERMAL_INDICATOR: COLD, COLD_COOL, COOL_WARM, WARM

Columns to keep are additional fields in the input file that the user wants 
retained in the output.  Fields need to be those that are unique per sample 
and not associated with the taxa.  For example, the fields used in qc.check();
Area_mi2, SurfaceArea, Density_m2, and Density_ft2. 

```{r MetricValues_Calc, eval=FALSE}
# Metrics, BCG, Bugs
library(BCGcalc)
library(readxl)

# PACIFIC NW
df.samps.bugs <- read_excel(system.file("./extdata/Data_BCG_PacNW.xlsx"
                                       , package="BCGcalc"))
myDF <- df.samps.bugs

# calculate
df.metric.values.bugs <- metric.values(myDF, "bugs")
View(df.metric.values.bugs)

```

Other tasks can be performed on the data once it is returned as a data frame.

```{r MetricValues_Extra, eval=FALSE}
library(BCGcalc)
library(reshape2)
library(DataExplorer)

# Convert to long format
df.long <- melt(df.metric.values.bugs, id.vars=c("SAMPLEID", "INDEX_NAME", "SITE_TYPE")
                          , variable.name="METRIC_NAME", value.name="METRIC_VALUE")
# Export for QC
write.table(df.long, "metric.values.tsv", col.names=TRUE, row.names=FALSE, sep="\t")

# DataExplorer Report
create_report(df.metric.values.bugs, "DataExplorer_Report_MetricValues.html")
create_report(df.samps.bugs, "DataExplorer_Report_BugSamples.html")
```

## Metric Scoring (Membership)
Metrics are scored according to a user defined table.  The membership scoring is BCG specific and results in a score in the range of 0 to 1.

The results are returned in a data frame in the long format.

```{r Import, eval=FALSE, echo=TRUE}
library(BCGcalc)
library(readxl)
library(knitr)

# Calculate Metrics
df.samps.bugs <- read_excel(system.file("./extdata/Data_BCG_PacNW.xlsx"
                                        , package="BCGcalc"))
myDF <- df.samps.bugs
df.metric.values.bugs <- metric.values(myDF, "bugs")

# Import Rules
df.rules <- read_excel(system.file("./extdata/Rules.xlsx"
                             , package="BCGcalc"), sheet="BCG_PacNW_v1_500ct") 

# Run function
df.Metric.Membership <- BCG.Metric.Membership(df.metric.values.bugs, df.rules.PacNW)

# show results
#View(df.Metric.Membership)

tbl.rules <- df.rules
tbl.rules.caption <- "Membership rules."

kable(tbl.rules, caption=tbl.rules.caption)

```

## Level Membership
The levels are determined according to the rules for a specific BCG model (e.g., Pacific Northwest low gradient).  The rules assign values (0-1) based on metric values.

```{r LevelMembership, eval=FALSE}
library(readxl)

# Calculate Metrics
df.samps.bugs <- read_excel(system.file("./extdata/Data_BCG_PacNW.xlsx"
                                        , package="BCGcalc"))
myDF <- df.samps.bugs
df.metric.values.bugs <- metric.values(myDF, "bugs")

# Import Rules
df.rules <- read_excel(system.file("./extdata/Rules.xlsx"
                             , package="BCGcalc"), sheet="BCG_PacNW_v1_500ct") 

# Calculate Metric Memberships
df.Metric.Membership <- BCG.Metric.Membership(df.metric.values.bugs, df.rules)

# Calculate Level Memberships
df.Level.Membership <- BCG.Level.Membership(df.Metric.Membership, df.rules)

# Show results
View(df.Level.Membership)
```

## Level Assignment
The level assignments are done according the values of the rules and metric level memberships.  The maximum level is designated as the primary level and the next highest value is assigned as the secondary level.

There is some QC to ensure the total membership equals 1 and a field to note if the assigned nears are a tie or close.

The user can also append the "flags" to the final results.  The code below changes all "FAIL" qc checks to "flag" and all "PASS" to NA before the append statement.

```{r LevelAssignment2, eval=TRUE, echo=TRUE}
# Example Data
library(BCGcalc)
library(readxl)
library(reshape2)
library(knitr)

# Calculate Metrics
df.samps.bugs <- read_excel(system.file("./extdata/Data_BCG_PacNW.xlsx"
                                        , package="BCGcalc"))
                                        
# Run Function
myDF <- df.samps.bugs
df.metric.values.bugs <- metric.values(myDF, "bugs") 

# Import Rules
df.rules <- read_excel(system.file("./extdata/Rules.xlsx"
                             , package="BCGcalc"), sheet="BCG_PacNW_v1_500ct") 

# Calculate Metric Memberships
df.Metric.Membership <- BCG.Metric.Membership(df.metric.values.bugs, df.rules)

# Calculate Level Memberships
df.Level.Membership <- BCG.Level.Membership(df.Metric.Membership, df.rules)

# Run Function
df.Levels <- BCG.Level.Assignment(df.Level.Membership)

# QC Checks (flags)
#
# Import Checks
df.checks <- read_excel(system.file("./extdata/MetricFlags.xlsx"
                                          , package="BCGcalc"), sheet="Flags") 
# Show QC checks table
tbl.checks <- df.checks
tbl.checks.caption <- "QC Checks"
kable(tbl.checks, caption = tbl.checks.caption)

# Rerun metrics including extra columns
myDF <- df.samps.bugs
myCols <- c("Area_mi2", "SurfaceArea", "Density_m2", "Density_ft2")
df.metric.values.bugs <- metric.values(myDF, "bugs", fun.cols2keep=myCols)                                         
# Run Function (qc.checks)
df.flags <- qc.checks(df.metric.values.bugs, df.checks)
# Change terminology; PASS/FAIL to NA/flag
df.flags[,"FLAG"][df.flags[,"FLAG"]=="FAIL"] <- "flag"
df.flags[, "FLAG"][df.flags[,"FLAG"]=="PASS"] <- NA

# long to wide format
df.flags.wide <- dcast(df.flags, SAMPLEID ~ CHECKNAME, value.var="FLAG")
# Calc number of "flag"s by row.
df.flags.wide$NumFlags <- rowSums(df.flags.wide=="flag", na.rm=TRUE)
# Rearrange columns
NumCols <- ncol(df.flags.wide)
df.flags.wide <- df.flags.wide[, c(1, NumCols, 2:(NumCols-1))]

# Merge Levels and Flags
df.Levels.Flags <- merge(df.Levels, df.flags.wide, by="SAMPLEID", all.x=TRUE)

# Show Results
tbl.Levels.Flags.caption = "Levels and Flags."
kable(head(df.Levels.Flags), caption = tbl.Levels.Flags.caption)

# Save Results
# write.table(df.Levels.Flags, "Levels.Flags.tsv"
#             , row.names=FALSE, col.names=TRUE, sep="\t")
            
# Summarize Results
tbl.flags.caption = "Flag Summary."
kable(table(df.flags[,"CHECKNAME"], df.flags[,"FLAG"], useNA="ifany"), caption = tbl.flags.caption)
```


## Other Tasks
There are some ancillary tasks that can be completed with the data that are a necessary part of data analysis and are included in the `BCGcalc` package for convenience.

### Master Taxa List
The Pacific Northwest benthic macroinvertebrate master taxa list is included for reference and can be saved to a file.

```{r BMT, eval=FALSE}
library(BCGcalc)

write.csv(TaxaMaster_Ben_BCG_PacNW, "TaxaMaster_Ben_BCG_PacNW_20180314.csv")
```

### Subsample (rarify)
Subsample (rarify) a biological sample to a fixed count.

Takes as an input a 3 column data frame (SampleID, TaxonID, Count) and returns a similar dataframe with revised Counts.

The other inputs are subsample size (target number of organisms in each sample) and seed. The seed is given so the results can be reproduced from the same input file. If no seed is given a random seed is used.  An easy seed to remember is the date of admission to the Union for each state (e.g., Washinton is 18891111).  These values can be found on Wikipedia on the right sidebar.

Returns a data frame with the same three columns but the abund field has been modified so the total count for each sample is no longer above the target (subsiz).

Code from USEPA Corvallis John Van Sickle R code for RIVPACS (v1.0, 2005-06-10).  Tweaked for addition of seed.

```{r Other_Rarify, eval=TRUE, echo=TRUE}
library(BCGcalc)
library(knitr)

# load bio data
DF.biodata <- data_bio2rarify
#dim(DF.biodata)
#View(DF.biodata)

# subsample
mySize <- 300
Seed.OR <- 18590214
Seed.WA <- 18891111
Seed.US <- 17760704
bugs.mysize <- rarify(inbug=DF.biodata, sample.ID="SampID"
                     ,abund="N_taxa",subsiz=mySize, mySeed=Seed.US)
#dim(bugs.mysize)
#View(bugs.mysize)

# Compare pre- and post- subsample counts
df.compare <- merge(DF.biodata, bugs.mysize, by=c("SampID", "TaxaID")
                    , suffixes = c("_500","_300"))
df.compare <- df.compare[,c("SampID", "TaxaID", "N_taxa_500", "N_taxa_300")]
#View(df.compare)

tbl.compare <- head(df.compare)
tbl.compare.caption <- "First few rows of original and rarified data."
kable(tbl.compare, caption=tbl.compare.caption)

tbl.totals <- aggregate(cbind(N_taxa_500, N_taxa_300) ~ SampID, df.compare, sum)
tbl.totals.caption <- "Comparison of total individuals per sample."
kable(tbl.totals, caption=tbl.totals.caption)

# save the data
#write.table(bugs.mysize,paste("bugs",mySize,"txt",sep="."),sep="\t")

```

### Flags
Specific to some programs there are QC checks on the samples that should be performed.  For example, minimum and maximum number of organisms to be a valid sample.

This function uses an imported data frame to compare calcualted metrics and gives a Pass or Fail evaluation to "flag" the sample for the user.

The QC checks are matched against the data on Index Name, Region, and Metric Name.  Only those that match are evaluated.  Valid symbols are those used by R; <, >, <=, >=, ==, and !=.
```{r Other_Flags, eval=TRUE, echo=TRUE}
library(readxl)
library(BCGcalc)
library(knitr)

# Calculate Metrics
df.samps.bugs <- read_excel(system.file("./extdata/Data_BCG_PacNW.xlsx"
                                        , package="BCGcalc"))
myDF <- df.samps.bugs
df.metric.values.bugs <- metric.values(myDF, "bugs")

# Import Checks
df.checks <- read_excel(system.file("./extdata/MetricFlags.xlsx"
                                          , package="BCGcalc"), sheet="Flags") 

# Run function
df.flags <- qc.checks(df.metric.values.bugs, df.checks)

# Show QC checks table
tbl.checks <- df.checks
tbl.checks.caption <- "QC Checks"
kable(tbl.checks, caption = tbl.checks.caption)

# Show results summary
tbl.results <- table(df.flags[,"CHECKNAME"], df.flags[,"FLAG"], useNA="ifany")
tbl.results.caption <- "QC Check Results"
kable(tbl.results, caption = tbl.results.caption)
```

### Unformated Data
The flexibility of R allows the user to get data from a multitude of sources and then manipulate (munge) it to fit the format needed for the functions in `BCGcalc`.  The example below shows how to import a file, add slope from a 2nd file, and to make a few changes to the data in order to use it with the package.  When the data source is fixed this routine can be modified and then used on all future datasets to prepare them for use with `BCGcalc`.

```{r DataMunge}
# Setup
library(readxl)
library(dplyr)
library(BCGcalc)
library(knitr)

# Read File
## FileName
fn.data <- system.file("./extdata/ExampleMunge_UnformatedData.xlsx"
                       , package="BCGcalc")
## Worksheet
sh.data <- "SamplesWithBioticAttributesAndR"
## Import
### set "guess" to a large number to avoid type being wrong
df.data <- read_excel(fn.data, sheet = sh.data, guess_max=12000)
dim(df.data)
kable(head(df.data), caption = "Unformatted Data")

# Munge
## Col Names
### convert to upper case
names(df.data) <- toupper(names(df.data))
### Rename Columns (base R) [dplyr::rename not working]
names(df.data)[names(df.data)=="SAMPLE ID"] <- "SAMPLEID"
names(df.data)[names(df.data)=="TAXON"] <- "TAXAID"
names(df.data)[names(df.data)=="SAMPLE ID"] <- "SAMPLEID"
names(df.data)[names(df.data)=="QUANTITY SUBSAMPLING"] <- "N_TAXA"
#names(df.data)[names(df.data)=="HILSENHOFF BIOTIC TOLERANCE INDEX"] <- "TOLVAL"
# df.data <- df.data %>% rename("SAMPLEID"="SAMPLE ID"
#                              , "TAXAID"="TAXON"
#                              , "N_TAXA"="QUANTITY SUBSAMPLING"
#                              , "TOLVAL"="HILSENHOFF BIOTIC TOLERANCE INDEX"
#                              )
### Create columns
df.data$EXCLUDE    <- !df.data$UNIQUE
df.data$NONTARGET  <- df.data$`OUTSIDE PROTOCOL`
# df.data$FFG        <- NA
# df.data$FFG[df.data$PREDATOR==TRUE]  <- "PR"
# df.data$HABIT      <- NA
# df.data$HABIT[df.data$CLINGER==TRUE] <- "CN"
# df.data$LIFE_CYCLE <- NA
df.data$SITE_TYPE  <- NA
# df.data$BCG_ATTR   <- NA
# df.data$THERMAL_INDICATOR <- NA
df.data$INDEX_NAME <- "BCG_PacNW_v1_500ct"
df.data$SURFACEAREA <- df.data$`SURFACE AREA`
df.data$AREA_MI2 <- NA
df.data$DENSITY_M2 <- NA
df.data$DENSITY_FT2 <- NA


# Add slope (and then gradient for SiteType) from NHD+ v2
fn.slope <- system.file("./extdata/ExampleMunge_Slope.xlsx", package="BCGcalc")
df.slope <- read_excel(fn.slope)
names(df.slope) <- toupper(names(df.slope))
# merge files
df.comb.slope <- merge(df.data, df.slope, by.x="SITE CODE", by.y="SITE_CODE", all.x=TRUE)
# QC (rows)
dim(df.data)
dim(df.comb.slope)
nrow(df.data) == nrow(df.comb.slope)
df.comb.slope$SITE_TYPE <- df.comb.slope$`SLOPE CATEGORY`


# Update Taxa Attributes from Master Taxa List in Package
df.taxamaster <- TaxaMaster_Ben_BCG_PacNW
names(df.taxamaster) <- toupper(names(df.taxamaster))
## Assume phylogenetic information is correct.
col.auteco <- c("TAXAID", "BCG_ATTR", "THERMAL_INDICATOR", "LONG_LIVED", "FFG"
                , "HABIT", "LIFE_CYCLE", "TOLVAL")
df.comb.slope.auteco <- merge(df.comb.slope, df.taxamaster[, col.auteco]
                              , by.x="TAXAID", by.y="TAXAID", all.x=TRUE)
nrow(df.comb.slope) == nrow(df.comb.slope.auteco)


# Create Anlaysis File
col2keep <- c("SAMPLEID", "INDEX_NAME", "SITE_TYPE"
              , "AREA_MI2", "SURFACEAREA", "DENSITY_M2", "DENSITY_FT2"
              , "TAXAID", "N_TAXA", "EXCLUDE", "NONTARGET"
              , "PHYLUM", "SUBPHYLUM", "CLASS", "ORDER", "FAMILY", "SUBFAMILY"
              , "TRIBE", "GENUS"
              , "FFG", "HABIT", "LIFE_CYCLE", "TOLVAL", "BCG_ATTR", "THERMAL_INDICATOR")
df.analysis <- as.data.frame(df.comb.slope.auteco[, col2keep ])


# Calculate metrics
cols2keep <- c("AREA_MI2", "SURFACEAREA", "DENSITY_M2", "DENSITY_FT2")
df.metval <- metric.values(df.analysis, "bugs", fun.cols2keep = cols2keep)
kable(head(df.metval), caption = "BCGcalc metric.values")

```

### Saving Specific Metrics
At times the user may want to save only specific metrics.  The code below demonstrates  
how to select and save only certain metrics.  This could be done in a separate R notebook.  
For more detail on using R Notebooks see https://bookdown.org/yihui/rmarkdown/notebook.html

```{r SelectMetrics}
library(BCGcalc)
library(readxl)
library(knitr)
# Load Data
df.data <- read_excel(system.file("./extdata/Data_BCG_PacNW.xlsx"
                                       , package="BCGcalc"))
# Columns to keep
myCols <- c("Area_mi2", "SurfaceArea", "Density_m2", "Density_ft2")
# Run Function
df.metval <- metric.values(df.data, "bugs", fun.cols2keep=myCols)
# View Results
#View(df.metval)
# Metrics of Interest
## thermal indicator (_ti_)
#names(df.metval)[grepl("_ti_", names(df.metval))]
col.met2keep <- c("ni_total", "nt_total", "nt_ti_c", "nt_ti_cc", "nt_ti_cw"
                , "nt_ti_w", "pi_ti_c", "pi_ti_cc", "pi_ti_cw", "pi_ti_w"
                , "pt_ti_c", "pt_ti_cc", "pt_ti_cw", "pt_ti_w")
col.ID <- c("SAMPLEID", toupper(myCols), "INDEX_NAME", "SITE_TYPE")
# Ouput
df.metval.ci <- df.metval[, c(col.ID, col.met2keep)]
# RMD table
kable(df.metval.ci[1:10, ], caption = "Select Metrics")

# Save (commented out)
# write.table(df.metval.ci, "metrics.thermalindicators.tsv"
#             , col.names=TRUE, row.names=FALSE, sep="\t")
```

