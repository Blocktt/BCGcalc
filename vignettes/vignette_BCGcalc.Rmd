---
title: "Vignette, BCGcalc"
author: "Erik.Leppo@tetratech.com"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette, QW}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
<!-- Data is in vignettes\data folder  -->
```{r rmd_setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```
# Purpose
The `BCGcalc` package was created to enable users to implement a model created Biological Condition Gradient and apply it to their data.  This vignette will cover the basics going from raw data to model results.

Any of the code in this Vignette can be copy and pasted to an R session and it will produce the same results as shown here.  Each section of code (gray box) is independant such that no other code needs to be run except what is in that section.  Thus, there is some repetition of steps between sections.

No files are exported in the examples in the vignette.  All "write" statements have been commented out.  If you wish to save the output remove the "#" from before each line of code.  Several different "write" functions were used in the examples.  This was intentional such that intermediate files are output at TSV (tab-separated values) files and final results are output as CSV (comma-separated values) files.  Both formats will open in Excel.

# Background
When applying the BCG, users should keep in mind that they can run any data through the model and get a result. However, if samples do not meet the criteria below, results should be interpreted with caution because they are outside the experience of the BCG model. 

## Criteria
*	Size: wadeable streams with drainage areas ranging from 1 to 100 mi2 

*	Geographic area: Puget Lowlands (eco code 2) and Willamette Valley (eco code 3) EPA level3 ecoregions

*	Stream type: freshwater, perennial; no unique habitats (such as springs and seeps)

*	Target number of organisms: 500-count (subsampled to 600 total individuals where needed)

*	Sampling area: ≥8 ft2

*	Level of taxonomic resolution: lowest practical level except for mites, which should be collapsed to the Order-level (Trombidiformes)

*	Collection gear: D-Frame kick-nets with 500-micrometer net mesh

*	Collection method: a targeted “riffle only” sampling scheme (like those used by King County and ODEQ) or WA ECY’s multi-habitat, ‘reach-wide’ sampling scheme

*	Collection period: July through October

Results should be interpreted with caution if they are flagged for any of the criteria listed in Appendix A (e.g., brackish influence, extreme dominance by one or two taxa).

## Input file
The user must generate the input file to run through the BCGcalc R tool (which then calculates metric values, metric membership values, BCG level membership and BCG level assignments). The R code references the required fields (see Table 1) in the input file when making these calculations (note: when creating column headings in the input file, the user should utilize the naming scheme in the first column of Table 1). The BCG workgroup went through a lengthy process to reach consensus on the BCG attribute assignments (BCG_Attr) for the Puget Lowlands and Willamette Valley (Stamp and Gerritsen 2018). Several of the BCG rules are based on BCG attribute metrics. Thus, for the BCG model results to be accurate and valid, users should make sure the BCG attributes in their input file match with those that are in the Excel file titled ‘TaxaMaster_Bug_BCG_PacNW_v1.’ If the input file contains taxa that are not on this list, the user should enter the appropriate phylogenetic information and a ‘NA’ in the ‘BCG_Attr’ field.

## Metric calculations
The BCGcalc R tool can be used to calculate a multitude of metrics (beyond the 12 that are used in the BCG model), including thermal indicator, FFG, habit, tolerance value and life cycle metrics. The BCG workgroup went through a lengthy process to reach consensus on the thermal indicator designations for the Puget Lowlands and Willamette Valley (Stamp and Gerritsen 2018) but did not address the other attributes at a regional scale. If the FFG, habit, tolerance value and life cycle attribute fields are utilized, those designations need to come from each entity. Users can calculate the full suite of metrics or adapt the code so that the output only includes a subset of metrics (for example, you may want to limit the output to only the 12 metrics used in the BCG model). Examples of R code that can be used to pull subsets of metrics can be found in the ‘Saving Specific Metrics’ section of the vignette.

## Key files

*	vignette_BCGcalc – html file that covers the basics going from raw data to BCG model results

*	TaxaMaster_Bug_BCG_PacNW_v1 – Excel file that is not referenced by the R code; rather its purpose is to help users create their input data files. The file contains the taxa list from the Puget Lowlands and Willamette Valley BCG project, and associated attribute information (NonTarget, BCG attribute, Thermal_Indicator, FFG, Habit, LifeCycle, TolVal). Important notes:
 
    +	When users create input files, they should make sure the BCG attribute assignments match with the designations in this file. 

    +	Thermal_Indicator assignments were based on temperature tolerance analyses and expert elicitation for the Puget Lowlands and Willamette Valley.
	For detailed information on how these designations were made, see the Excel file titled ‘PL_WV_ThermalIndicator_20180326’

    +	Functional feeding group (FFG) assignments were compiled from ODEQ, WA ECY and the EPA National Aquatic Resource Surveys (NARS) (using majority rules; the BCG work group did not try to reach consensus on these)

    +	The Habit, LifeCycle & TolVal fields (highlighted in red) have placeholders (the BCG work group did not try to reach consensus on these; if a user wants to generate metrics based on these fields, they will need to use their own data to populate these fields)

*	MetricNames – Excel file that contains a list of all the potential metrics that can be calculated with the BCGcalc R tool. This file is not referenced by the R code.

*	Rules - Excel file that contains worksheets with the BCG rules that the R code references; the worksheet titled ‘BCG_PacNW_v1_500ct’ is used for the 500-count model. 

*	Data_BCG_PacNW – Excel file that is automatically uploaded to ‘extdata’ folder when you install the R package (on my computer, it is located here: C:\Programs\R\R-3.4.1\library\BCGcalc\extdata). It is an example of an input file (it contains data for the 678 samples that were in the BCG calibration dataset). You can use it as a template when you prepare your own input data for the R code. Column headings for required fields are highlighted in green.

## Disclaimer
Version 1 of the BCG model has known limitations and will need further testing in coming years. The models should be regarded as beta versions, with potential for refinement over time as the models are used with new data.

## Literature cited
Stamp, J. and J. Gerritsen. 2018. Calibration of the Biological Condition Gradient (BCG) for Macroinvertebrate Assemblages in Puget Lowland/Willamette Valley Freshwater Wadeable Streams. Prepared by Tetra Tech for the US EPA Office of Water, Office of Science and Technology and US EPA Region 10

# Installing BCGcalc
The package is hosted on GitHub (https://github.com/leppott/BCGcalc) and can be installed using the following lines of code.  It is necssary to install the `devtools` package.  

```{r Pkg_Install, eval=FALSE}
# Installing the BCGcalc library (with the vignette) from GitHub
library(devtools) 
install_github("leppott/BCGcalc", force=TRUE, build_vignettes=TRUE)
```

# Help
After the BCGcalc package has been installed running the following line of code will open the help file.
```{r Pkg_Help, eval=FALSE}
help(package="BCGcalc")
```

# Data Preparation
The user must generate the input file. The R code references the required fields (see Table 1 in the README file) in the input file when making these calculations. The BCG workgroup went through a lengthy process to reach consensus on the BCG attribute assignments (BCG_Attr) for the Puget Lowlands and Willamette Valley (Stamp and Gerritsen 2018). Several of the BCG rules are based on BCG attribute metrics. Thus, for the BCG model results to be accurate and valid, users should make sure the BCG attributes in their input file match with those that are in the Excel file titled ‘TaxaMaster_Bug_BCG_PacNW_v1.’ If the input file contains taxa that are not on this list, the user should enter the appropriate phylogenetic information and a ‘NA’ in the ‘BCG_Attr’ field

The BCG model was calibrated for 500-count samples. If any of your samples have more than 600 organisms, run your dataset through the Rarify (subsampling) routine (600 is +20% of the 500-count target). This is done to make richness metrics comparable across the 500-count samples. A 300-count model is being developed as well.

All benthic macroinvertebrate taxa should be identified to the appropriate operational taxonomic unit (OTU).  For example, all water mites should be only identified to order.  Any non-count taxa should be identified in the “Exclude” field as “TRUE”. These taxa will be excluded from taxa richness metrics (but will count for all others). Excluded taxa are ambiguous taxa (on a sample basis), i.e., the parent taxa when child taxa are present. For example, the parent taxa Chironomidae would be xcluded when the child taxa Tanytarsini is present.

Both would be excluded when Tanytarsus is present. Any non-target taxa should be identified in the “NonTarget” field as “TRUE”. Non-target taxa are those that are not part of your intended capture list; e.g., fish, herps, water column taxa, or water surface taxa in a benthic sample. The target list will vary by program. The non-target taxa will be removed prior to any calculations. There are a number of required fields (see below) for metric to calculation.  If any fields are missing the user will be prompted as to which are missing and if the user wants to continue or quit. If the user continues the missing fields will be added but will be filled with zero or NA (as appropriate).  Any metrics based on the missing fields will not be valid.

Required Fields:

*	SAMPLEID (character or number, must be unique)

*	TAXAID (character or number, must be unique)

*	N_TAXA

*	EXCLUDE (valid values are TRUE and FALSE)

*	INDEX_NAME (must match INDEX_NAME in Rules and Flags)

*	SITE_TYPE (BCG or MMI site category; e.g., for BCG PacNW valid values are “hi” or “lo”)

*	NONTARGET (valid values are TRUE and FALSE)

*	PHYLUM, SUBPHYLUM, CLASS, ORDER, FAMILY, SUBFAMILY, TRIBE, GENUS

*	FFG, HABIT, LIFE_CYCLE, TOLVAL, BCG_ATTR, THERMAL_INDICATOR

    + Valid values for FFG: CG, CF, PR, SC, SH
    
    + Valid values for HABIT: BU, CB, CN, SP, SW
    
    + Valid values for LIFE_CYCLE: UNI, SEMI, MULTI
    
    + Valid values for THERMAL_INDICATOR: COLD, COLD_COOL, COOL_WARM, WARM
    
Columns to keep are additional fields in the input file that the user wants retained in the output. Fields need to be those that are unique per sample and not associated with the taxa. For example, the fields used in qc.check(); Area_mi2, SurfaceArea, Density_m2, and Density_ft2.

It is recommended that the user reviews the following files when preparing their data: 

*	BCGcalc_README_20180919 (Word doc)

*	TaxaMaster_Bug_BCG_PacNW_v1 (Excel file) – make sure your BCG attribute assignments match these 

*	Data_BCG_PacNW (Excel file) – could potentially be used as a template (green column headings are required fields)

These files can be found in the ‘extdata’ folder after installing the package.

The master taxa list is a data object in the package.  It can be viewed or saved with the code below.  
```{r View_TaxaMaster, eval=FALSE}
library(BCGcalc)

View(TaxaMaster_Ben_BCG_PacNW)

# Save to working directory
#write.csv(TaxaMaster_Ben_BCG_PacNW, "TaxaMaster_Ben_BCG_PacNW_20180927.csv")
```

The first few lines are also displayed below.
```{r head_TaxaMaster, echo=FALSE, eval=TRUE}
library(BCGcalc)
library(knitr)
kable(head(TaxaMaster_Ben_BCG_PacNW), caption="PacNW BCG Master Taxa")
```

# Package Functions
The suite of functions in the `BCGcalc` package are presented int two sections.  The first section will cover the core functions from metric calculation to model results.  The example will cover all steps in a single example.  Additional functions will be covered individually and each function will have its own self contained example.

1. BCG Core Functions

    A. Metric calculation
    
    B. Metric scoring (membership)

    C. Level membership

    D. Level assignment

    E. Add flags
    
2. Additional (Optional) Functions

    A. Rarify (subsampling)
    
    B. Saving selected metrics

    C. Summary of flagged samples

    D. Writing code to format new data files

    E. Other formatting options
    
    F. BCG level 1 signal (to be developed)
    
    G. 300-count model ()
    
    H. Exclude taxa assignment (to be developed)
    
## BCGcalc Core Functions
Once your input file is formatted and ready to go, the next step is to run it through the R code. The R code generates BCG level assignments for each sample. Along the way it calculates the following: metric values, metric membership values, BCG level membership and BCG level assignments. It also adds flags to the BCG level assignment file. 

Below are two examples of R code that can be used to generate BCG model outputs. This code is written for **500**-count samples (which is what the PacNW BCG model is calibrated for). 

The first example below is for test data that is automatically downloaded onto your computer when you install the BCGcalc R package. If it’s your first time running this code, and you are a novice R user, we recommend trying this code first (you can follow it verbatim, no edits needed, and it should generate the desired output).

The second example is for an ‘outside’ data file (to simulate you running the R code on your own data). Before running this on your own data, you will need to update the directories, the name of the input file and potentially a few other fields. In this example, the input file is called ‘ExampleDataFile.xlsx’.   Remember - when you type in your working directory (in this example, E:\\BCG_R10\\R_tool\\Example), remember that you either need two backslashes \\ or one forward slash /. If you copy and paste the directory from your Windows File Explorer window, it comes in as one backslash so you will need to manually correct this.

If you decide to run the example below, the following five files will appear in your working directory (note: file names will differ depending on which set of code you run – this is for example #1)

*	metrics.values.Test.tsv

*	Metric.Membership.Test.tsv

*	Level.Membership.Test.tsv

*	Levels.Flags.Test.csv

### Example, Test Data
The code below uses the test data that is contained in the package and is already of the proper format.

```{r Core_Test, eval=FALSE}
# Packages
library(BCGcalc)
library(readxl)
library(reshape2)

# Import
df.samps.bugs <- read_excel(system.file("./extdata/Data_BCG_PacNW.xlsx"
                                        , package="BCGcalc"))

# QC for TRUE/FALSE (both ok) 
# Exclude to TRUE/FALSE
table(df.samps.bugs$Exclude)
# NonTarget to TRUE/FALSE
table(df.samps.bugs$NonTarget)

# 1.A. Calculate Metrics
# Extra columns to keep in results
keep.cols <- c("Area_mi2", "SurfaceArea", "Density_m2", "Density_ft2")
# Run Function
df.metrics <- metric.values(df.samps.bugs, "bugs", fun.cols2keep = keep.cols)
# QC
dim(df.metrics)
View(df.metrics)
# Save
write.table(df.metrics, "Metric.Values.Test.tsv", col.names=TRUE, row.names=FALSE, sep="\t")

# 1.B. Metric Membership
# Import Rules
df.rules <- read_excel(system.file("./extdata/Rules.xlsx"
                             , package="BCGcalc"), sheet="BCG_PacNW_v1_500ct") 
# Run function
df.Metric.Membership <- BCG.Metric.Membership(df.metrics, df.rules)
# Show Results
View(df.Metric.Membership)
# Save Results
write.table(df.Metric.Membership, "Metric.Membership.Test.tsv"
              , row.names=FALSE, col.names=TRUE, sep="\t")

# 1.C. Level Assignment
# Run Function
df.Level.Membership <- BCG.Level.Membership(df.Metric.Membership, df.rules)
# Show results
View(df.Level.Membership)
# Save Results
write.table(df.Level.Membership, "Level.Membership.Test.tsv"
             , row.names=FALSE, col.names=TRUE, sep="\t")

# 1.D. Level Membership
# Run Function
df.Levels <- BCG.Level.Assignment(df.Level.Membership)
# QC Checks (flags)
#
# Import Checks
df.checks <- read_excel(system.file("./extdata/MetricFlags.xlsx"
                                          , package="BCGcalc"), sheet="Flags") 
# Run Function
df.flags <- qc.checks(df.metric.values.bugs, df.checks)
# Change terminology; PASS/FAIL to NA/flag
df.flags[,"FLAG"][df.flags[,"FLAG"]=="FAIL"] <- "flag"
df.flags[, "FLAG"][df.flags[,"FLAG"]=="PASS"] <- NA

# long to wide format
df.flags.wide <- dcast(df.flags, SAMPLEID ~ CHECKNAME, value.var="FLAG")
# Calc number of "flag"s by row.
df.flags.wide$NumFlags <- rowSums(df.flags.wide=="flag", na.rm=TRUE)
# Rearrange columns
NumCols <- ncol(df.flags.wide)
df.flags.wide <- df.flags.wide[, c(1, NumCols, 2:(NumCols-1))]
# Merge Levels and Flags
df.Levels.Flags <- merge(df.Levels, df.flags.wide, by="SAMPLEID", all.x=TRUE)
# Show Results
View(df.Levels.Flags)
# Summarize Results
table(df.flags[,"CHECKNAME"], df.flags[,"FLAG"], useNA="ifany")
# Save Results
write.csv(df.Levels.Flags, "Levels.Flags.Test.csv")

```


### Example, New Data
The code below uses an example data set that is not properly formated.  The code goes through the steps of formatting the data.  This code simulates getting code from a database and the steps needed to prepare it for use with the `BCGcalc` package.

```{r Core_New, eval=FALSE}

```









----
old version
---


## Core Functions


### Metric Calculation
The `BCGcalc` package includes some example that will be used in this example.

The funtion metric.values generates 160+ different metrics for multi-metric indices as well as BCG specific metrics.  All metrics are calculated and reported back to the user in a data frame.

No manipulations of the taxa are performed by this routine.  
All benthic macroinvertebrate taxa should be identified to the appropriate 
operational taxonomic unit (OTU).  
Any non-count taxa should be identified in the "Exclude" field as "TRUE". 
These taxa will be excluded from taxa richness metrics (but will count for 
all others).  Excluded taxa are ambiguous taxa (on a sample basis), i.e., 
the parent taxa when child taxa are present.  For example, the parent taxa 
Chironomidae would be xcluded when the child taxa Tanytarsini is present.  
Both would be excluded when Tanytarsus is present.
Any non-target taxa should be identified in the "NonTarget" field as "TRUE". 
Non-target taxa are those that are not part of your intended capture list; 
e.g., fish,  herps, water column taxa, or water surface taxa in a benthic sample.
The target list will vary by program.
The non-target taxa will be removed prior to any calculations.
There are a number of required fields (see below) for metric to calculation.  
If any fields are missing the user will be prompted as to which are missing 
and if the user wants to continue or quit.  If the user continues the missing 
fields will be added but will be filled with zero or NA (as appropriate).  
Any metrics based on the missing fields will not be valid.

Required Fields:

* SAMPLEID (character or number, must be unique)

* TAXAID (character or number, must be unique)

* N_TAXA

* EXCLUDE (valid values are TRUE and FALSE)

* INDEX_NAME

* SITE_TYPE (BCG or MMI site category; e.g., for BCG PacNW valid values are "hi" or "lo")

* NONTARGET (valid values are TRUE and FALSE)

* PHYLUM, SUBPHYLUM, CLASS, ORDER, FAMILY, SUBFAMILY, TRIBE, GENUS

* FFG, HABIT, LIFE_CYCLE, TOLVAL, BCG_ATTR, THERMAL_INDICATOR

Valid values for FFG: CG, CF, PR, SC, SH

Valid values for HABIT: BU, CB, CN, SP, SW

Valid values for LIFE_CYCLE: UNI, SEMI, MULTI

Valid values for THERMAL_INDICATOR: COLD, COLD_COOL, COOL_WARM, WARM

Columns to keep are additional fields in the input file that the user wants 
retained in the output.  Fields need to be those that are unique per sample 
and not associated with the taxa.  For example, the fields used in qc.check();
Area_mi2, SurfaceArea, Density_m2, and Density_ft2. 

```{r MetricValues_Calc, eval=FALSE}
# Metrics, BCG, Bugs
library(BCGcalc)
library(readxl)

# PACIFIC NW
df.samps.bugs <- read_excel(system.file("./extdata/Data_BCG_PacNW.xlsx"
                                       , package="BCGcalc"))
myDF <- df.samps.bugs

# calculate
df.metric.values.bugs <- metric.values(myDF, "bugs")
View(df.metric.values.bugs)

```

Other tasks can be performed on the data once it is returned as a data frame.

```{r MetricValues_Extra, eval=FALSE}
library(BCGcalc)
library(reshape2)
library(DataExplorer)

# Convert to long format
df.long <- melt(df.metric.values.bugs, id.vars=c("SAMPLEID", "INDEX_NAME", "SITE_TYPE")
                          , variable.name="METRIC_NAME", value.name="METRIC_VALUE")
# Export for QC
write.table(df.long, "metric.values.tsv", col.names=TRUE, row.names=FALSE, sep="\t")

# DataExplorer Report
create_report(df.metric.values.bugs, "DataExplorer_Report_MetricValues.html")
create_report(df.samps.bugs, "DataExplorer_Report_BugSamples.html")
```

### Metric Scoring (Membership)
Metrics are scored according to a user defined table.  The membership scoring is BCG specific and results in a score in the range of 0 to 1.

The results are returned in a data frame in the long format.

```{r Import, eval=FALSE, echo=TRUE}
library(BCGcalc)
library(readxl)
library(knitr)

# Calculate Metrics
df.samps.bugs <- read_excel(system.file("./extdata/Data_BCG_PacNW.xlsx"
                                        , package="BCGcalc"))
myDF <- df.samps.bugs
df.metric.values.bugs <- metric.values(myDF, "bugs")

# Import Rules
df.rules <- read_excel(system.file("./extdata/Rules.xlsx"
                             , package="BCGcalc"), sheet="BCG_PacNW_v1_500ct") 

# Run function
df.Metric.Membership <- BCG.Metric.Membership(df.metric.values.bugs, df.rules.PacNW)

# show results
#View(df.Metric.Membership)

tbl.rules <- df.rules
tbl.rules.caption <- "Membership rules."

kable(tbl.rules, caption=tbl.rules.caption)

```

### Level Membership
The levels are determined according to the rules for a specific BCG model (e.g., Pacific Northwest low gradient).  The rules assign values (0-1) based on metric values.

```{r LevelMembership, eval=FALSE}
library(readxl)

# Calculate Metrics
df.samps.bugs <- read_excel(system.file("./extdata/Data_BCG_PacNW.xlsx"
                                        , package="BCGcalc"))
myDF <- df.samps.bugs
df.metric.values.bugs <- metric.values(myDF, "bugs")

# Import Rules
df.rules <- read_excel(system.file("./extdata/Rules.xlsx"
                             , package="BCGcalc"), sheet="BCG_PacNW_v1_500ct") 

# Calculate Metric Memberships
df.Metric.Membership <- BCG.Metric.Membership(df.metric.values.bugs, df.rules)

# Calculate Level Memberships
df.Level.Membership <- BCG.Level.Membership(df.Metric.Membership, df.rules)

# Show results
View(df.Level.Membership)
```

### Level Assignment
The level assignments are done according the values of the rules and metric level memberships.  The maximum level is designated as the primary level and the next highest value is assigned as the secondary level.

There is some QC to ensure the total membership equals 1 and a field to note if the assigned nears are a tie or close.

The user can also append the "flags" to the final results.  The code below changes all "FAIL" qc checks to "flag" and all "PASS" to NA before the append statement.

```{r LevelAssignment2, eval=TRUE, echo=TRUE}
# Example Data
library(BCGcalc)
library(readxl)
library(reshape2)
library(knitr)

# Calculate Metrics
df.samps.bugs <- read_excel(system.file("./extdata/Data_BCG_PacNW.xlsx"
                                        , package="BCGcalc"))
                                        
# Run Function
myDF <- df.samps.bugs
df.metric.values.bugs <- metric.values(myDF, "bugs") 

# Import Rules
df.rules <- read_excel(system.file("./extdata/Rules.xlsx"
                             , package="BCGcalc"), sheet="BCG_PacNW_v1_500ct") 

# Calculate Metric Memberships
df.Metric.Membership <- BCG.Metric.Membership(df.metric.values.bugs, df.rules)

# Calculate Level Memberships
df.Level.Membership <- BCG.Level.Membership(df.Metric.Membership, df.rules)

# Run Function
df.Levels <- BCG.Level.Assignment(df.Level.Membership)

# QC Checks (flags)
#
# Import Checks
df.checks <- read_excel(system.file("./extdata/MetricFlags.xlsx"
                                          , package="BCGcalc"), sheet="Flags") 
# Show QC checks table
tbl.checks <- df.checks
tbl.checks.caption <- "QC Checks"
kable(tbl.checks, caption = tbl.checks.caption)

# Rerun metrics including extra columns
myDF <- df.samps.bugs
myCols <- c("Area_mi2", "SurfaceArea", "Density_m2", "Density_ft2")
df.metric.values.bugs <- metric.values(myDF, "bugs", fun.cols2keep=myCols)                                         
# Run Function (qc.checks)
df.flags <- qc.checks(df.metric.values.bugs, df.checks)
# Change terminology; PASS/FAIL to NA/flag
df.flags[,"FLAG"][df.flags[,"FLAG"]=="FAIL"] <- "flag"
df.flags[, "FLAG"][df.flags[,"FLAG"]=="PASS"] <- NA

# long to wide format
df.flags.wide <- dcast(df.flags, SAMPLEID ~ CHECKNAME, value.var="FLAG")
# Calc number of "flag"s by row.
df.flags.wide$NumFlags <- rowSums(df.flags.wide=="flag", na.rm=TRUE)
# Rearrange columns
NumCols <- ncol(df.flags.wide)
df.flags.wide <- df.flags.wide[, c(1, NumCols, 2:(NumCols-1))]

# Merge Levels and Flags
df.Levels.Flags <- merge(df.Levels, df.flags.wide, by="SAMPLEID", all.x=TRUE)

# Show Results
tbl.Levels.Flags.caption = "Levels and Flags."
kable(head(df.Levels.Flags), caption = tbl.Levels.Flags.caption)

# Save Results
# write.table(df.Levels.Flags, "Levels.Flags.tsv"
#             , row.names=FALSE, col.names=TRUE, sep="\t")
            
# Summarize Results
tbl.flags.caption = "Flag Summary."
kable(table(df.flags[,"CHECKNAME"], df.flags[,"FLAG"], useNA="ifany"), caption = tbl.flags.caption)
```

### Flags
Specific to some programs there are QC checks on the samples that should be performed.  For example, minimum and maximum number of organisms to be a valid sample.

This function uses an imported data frame to compare calcualted metrics and gives a Pass or Fail evaluation to "flag" the sample for the user.

The QC checks are matched against the data on Index Name, Region, and Metric Name.  Only those that match are evaluated.  Valid symbols are those used by R; <, >, <=, >=, ==, and !=.
```{r Other_Flags, eval=TRUE, echo=TRUE}
library(readxl)
library(BCGcalc)
library(knitr)

# Calculate Metrics
df.samps.bugs <- read_excel(system.file("./extdata/Data_BCG_PacNW.xlsx"
                                        , package="BCGcalc"))
myDF <- df.samps.bugs
df.metric.values.bugs <- metric.values(myDF, "bugs")

# Import Checks
df.checks <- read_excel(system.file("./extdata/MetricFlags.xlsx"
                                          , package="BCGcalc"), sheet="Flags") 

# Run function
df.flags <- qc.checks(df.metric.values.bugs, df.checks)

# Show QC checks table
tbl.checks <- df.checks
tbl.checks.caption <- "QC Checks"
kable(tbl.checks, caption = tbl.checks.caption)

# Show results summary
tbl.results <- table(df.flags[,"CHECKNAME"], df.flags[,"FLAG"], useNA="ifany")
tbl.results.caption <- "QC Check Results"
kable(tbl.results, caption = tbl.results.caption)
```

## Additional (Optional) Functions
There are some ancillary tasks that can be completed with the data that are a necessary part of data analysis and are included in the `BCGcalc` package for convenience.

### Subsample (rarify)
The `rarify` function subsamples count data to a fixed count per sample.  It takes as an input a 3 column data frame (SampleID, TaxonID, Count) and returns a similar dataframe with revised Counts.  The names of the columns does not matter as they are specified in the code.  Any non-count taxa (e.g., fish in a bug sample) should be removed prior to using the `rarify` function.  The function code is from USEPA Corvallis John Van Sickle R code for RIVPACS (v1.0, 2005-06-10) and was tweaked for addition of user provided seed so repeatable results can be obtained.

The other inputs are subsample size (target number of organisms in each sample) and seed. The seed is given so the results can be reproduced from the same input file. If no seed is given a random seed is used.  An easy seed to remember is the date of admission to the Union for each state (e.g., Washinton is 18891111).  These values can be found on Wikipedia on the right sidebar.

If you are running the 500-count BCG model and any of your samples have more than 600 organisms (the upper limit for the model), you should randomly subsample your data to 600 (600 is +20% of the 500-count target). This is done to make richness metrics comparable across the 500-count samples. You can do this with the Rarify routine.

Save the input file.  The example uses CSV but other data types could be used.

Before you run the code below on your own data, you’ll need to update the directories, the name of the input file and potentially a few other fields. In this example, the input file is called ‘ExampleOrigto600.xlsx’. 

After you are done with the subsampling, bring the updated N_Taxa field into your input file (see example file titled ‘ExampleDataFile’; we retained the original data in an optional field called N_Taxa_orig). 

Then run your data file through the BCGcalc example code described previously in this document.







```{r Other_Rarify, eval=TRUE, echo=TRUE}
library(BCGcalc)
library(knitr)

# load bio data
DF.biodata <- data_bio2rarify
#dim(DF.biodata)
#View(DF.biodata)

# subsample
mySize <- 300
Seed.OR <- 18590214
Seed.WA <- 18891111
Seed.US <- 17760704
bugs.mysize <- rarify(inbug=DF.biodata, sample.ID="SampID"
                     ,abund="N_taxa",subsiz=mySize, mySeed=Seed.US)
#dim(bugs.mysize)
#View(bugs.mysize)

# Compare pre- and post- subsample counts
df.compare <- merge(DF.biodata, bugs.mysize, by=c("SampID", "TaxaID")
                    , suffixes = c("_500","_300"))
df.compare <- df.compare[,c("SampID", "TaxaID", "N_taxa_500", "N_taxa_300")]
#View(df.compare)

tbl.compare <- head(df.compare)
tbl.compare.caption <- "First few rows of original and rarified data."
kable(tbl.compare, caption=tbl.compare.caption)

tbl.totals <- aggregate(cbind(N_taxa_500, N_taxa_300) ~ SampID, df.compare, sum)
tbl.totals.caption <- "Comparison of total individuals per sample."
kable(tbl.totals, caption=tbl.totals.caption)

# save the data
#write.table(bugs.mysize,paste("bugs",mySize,"txt",sep="."),sep="\t")

```

# Metric Calculation, Saving Specific Metrics
You can adapt the code so that the metric calculation output only includes a subset of the metrics.

For example, you may only want to view the metrics that go into the BCG model calculation. Below are two examples of code for saving specific metrics -

*	BCG – this output is limited to the 12 metrics that go into the BCG model calculation

*	Thermal indicator metrics (ti) – this has richness and percent composition metrics for thermal indicator taxa (c=cold, cc = cold/cool, cw = cool/warm, w= warm)

You can do this one of two ways.

1. Knowing the names of the metrics use them as input in the `metric.values` function.

2. Examine the results file and select certain metrics to keep.

```{r MetricValues_Keep1}
library(BCGcalc)
library(readxl)
library(knitr)
# Load Data
df.data <- read_excel(system.file("./extdata/Data_BCG_PacNW.xlsx"
                                       , package="BCGcalc"))
# Columns to keep
myCols <- c("Area_mi2", "SurfaceArea", "Density_m2", "Density_ft2")
# Run Function
df.metval <- metric.values(df.data, "bugs", fun.cols2keep=myCols)
# View Results
#View(df.metval)
# Metrics of Interest
## thermal indicator (_ti_)
#names(df.metval)[grepl("_ti_", names(df.metval))]
col.met2keep <- c("ni_total", "nt_total", "nt_ti_c", "nt_ti_cc", "nt_ti_cw"
                , "nt_ti_w", "pi_ti_c", "pi_ti_cc", "pi_ti_cw", "pi_ti_w"
                , "pt_ti_c", "pt_ti_cc", "pt_ti_cw", "pt_ti_w")
col.ID <- c("SAMPLEID", toupper(myCols), "INDEX_NAME", "SITE_TYPE")
# Ouput
df.metval.ci <- df.metval[, c(col.ID, col.met2keep)]
# RMD table
kable(df.metval.ci[1:10, ], caption = "Select Metrics")

# Save (commented out)
# write.table(df.metval.ci, "metrics.thermalindicators.tsv"
#             , col.names=TRUE, row.names=FALSE, sep="\t")
```


```{r MetricValues_Keep2}
library(BCGcalc)
library(readxl)
library(knitr)
# Load Data
df.data <- read_excel(system.file("./extdata/Data_BCG_PacNW.xlsx"
                                       , package="BCGcalc"))
# Columns to keep
myCols <- c("Area_mi2", "SurfaceArea", "Density_m2", "Density_ft2")
# Run Function
df.metval <- metric.values(df.data, "bugs", fun.cols2keep=myCols)
# View Results
#View(df.metval)
# Metrics of Interest
## thermal indicator (_ti_)
#names(df.metval)[grepl("_ti_", names(df.metval))]
col.met2keep <- c("ni_total", "nt_total", "nt_ti_c", "nt_ti_cc", "nt_ti_cw"
                , "nt_ti_w", "pi_ti_c", "pi_ti_cc", "pi_ti_cw", "pi_ti_w"
                , "pt_ti_c", "pt_ti_cc", "pt_ti_cw", "pt_ti_w")
col.ID <- c("SAMPLEID", toupper(myCols), "INDEX_NAME", "SITE_TYPE")
# Ouput
df.metval.ci <- df.metval[, c(col.ID, col.met2keep)]
# RMD table
kable(df.metval.ci[1:10, ], caption = "Select Metrics")

# Save (commented out)
# write.table(df.metval.ci, "metrics.thermalindicators.tsv"
#             , col.names=TRUE, row.names=FALSE, sep="\t")
```

# Flags

Results should be interpreted with caution if they are flagged for any of the criteria listed below. If you run the BCGcalc code above, columns with flags will be added into the file with the Level Assignments.
Below is example code. If you use this code, your input data file should include the following three columns: 

```{r Flags}

```

# Writing code to format new data files

### Unformated Data
The flexibility of R allows the user to get data from a multitude of sources and then manipulate (munge) it to fit the format needed for the functions in `BCGcalc`.  The example below shows how to import a file, add slope from a 2nd file, and to make a few changes to the data in order to use it with the package.  When the data source is fixed this routine can be modified and then used on all future datasets to prepare them for use with `BCGcalc`.

```{r DataMunge}
# Setup
library(readxl)
library(dplyr)
library(BCGcalc)
library(knitr)

# Read File
## FileName
fn.data <- system.file("./extdata/ExampleMunge_UnformatedData.xlsx"
                       , package="BCGcalc")
## Worksheet
sh.data <- "SamplesWithBioticAttributesAndR"
## Import
### set "guess" to a large number to avoid type being wrong
df.data <- read_excel(fn.data, sheet = sh.data, guess_max=12000)
dim(df.data)
kable(head(df.data), caption = "Unformatted Data")

# Munge
## Col Names
### convert to upper case
names(df.data) <- toupper(names(df.data))
### Rename Columns (base R) [dplyr::rename not working]
names(df.data)[names(df.data)=="SAMPLE ID"] <- "SAMPLEID"
names(df.data)[names(df.data)=="TAXON"] <- "TAXAID"
names(df.data)[names(df.data)=="SAMPLE ID"] <- "SAMPLEID"
names(df.data)[names(df.data)=="QUANTITY SUBSAMPLING"] <- "N_TAXA"
#names(df.data)[names(df.data)=="HILSENHOFF BIOTIC TOLERANCE INDEX"] <- "TOLVAL"
# df.data <- df.data %>% rename("SAMPLEID"="SAMPLE ID"
#                              , "TAXAID"="TAXON"
#                              , "N_TAXA"="QUANTITY SUBSAMPLING"
#                              , "TOLVAL"="HILSENHOFF BIOTIC TOLERANCE INDEX"
#                              )
### Create columns
df.data$EXCLUDE    <- !df.data$UNIQUE
df.data$NONTARGET  <- df.data$`OUTSIDE PROTOCOL`
# df.data$FFG        <- NA
# df.data$FFG[df.data$PREDATOR==TRUE]  <- "PR"
# df.data$HABIT      <- NA
# df.data$HABIT[df.data$CLINGER==TRUE] <- "CN"
# df.data$LIFE_CYCLE <- NA
df.data$SITE_TYPE  <- NA
# df.data$BCG_ATTR   <- NA
# df.data$THERMAL_INDICATOR <- NA
df.data$INDEX_NAME <- "BCG_PacNW_v1_500ct"
df.data$SURFACEAREA <- df.data$`SURFACE AREA`
df.data$AREA_MI2 <- NA
df.data$DENSITY_M2 <- NA
df.data$DENSITY_FT2 <- NA


# Add slope (and then gradient for SiteType) from NHD+ v2
fn.slope <- system.file("./extdata/ExampleMunge_Slope.xlsx", package="BCGcalc")
df.slope <- read_excel(fn.slope)
names(df.slope) <- toupper(names(df.slope))
# merge files
df.comb.slope <- merge(df.data, df.slope, by.x="SITE CODE", by.y="SITE_CODE", all.x=TRUE)
# QC (rows)
dim(df.data)
dim(df.comb.slope)
nrow(df.data) == nrow(df.comb.slope)
df.comb.slope$SITE_TYPE <- df.comb.slope$`SLOPE CATEGORY`


# Update Taxa Attributes from Master Taxa List in Package
df.taxamaster <- TaxaMaster_Ben_BCG_PacNW
names(df.taxamaster) <- toupper(names(df.taxamaster))
## Assume phylogenetic information is correct.
col.auteco <- c("TAXAID", "BCG_ATTR", "THERMAL_INDICATOR", "LONG_LIVED", "FFG"
                , "HABIT", "LIFE_CYCLE", "TOLVAL")
df.comb.slope.auteco <- merge(df.comb.slope, df.taxamaster[, col.auteco]
                              , by.x="TAXAID", by.y="TAXAID", all.x=TRUE)
nrow(df.comb.slope) == nrow(df.comb.slope.auteco)


# Create Anlaysis File
col2keep <- c("SAMPLEID", "INDEX_NAME", "SITE_TYPE"
              , "AREA_MI2", "SURFACEAREA", "DENSITY_M2", "DENSITY_FT2"
              , "TAXAID", "N_TAXA", "EXCLUDE", "NONTARGET"
              , "PHYLUM", "SUBPHYLUM", "CLASS", "ORDER", "FAMILY", "SUBFAMILY"
              , "TRIBE", "GENUS"
              , "FFG", "HABIT", "LIFE_CYCLE", "TOLVAL", "BCG_ATTR", "THERMAL_INDICATOR")
df.analysis <- as.data.frame(df.comb.slope.auteco[, col2keep ])


# Calculate metrics
cols2keep <- c("AREA_MI2", "SURFACEAREA", "DENSITY_M2", "DENSITY_FT2")
df.metval <- metric.values(df.analysis, "bugs", fun.cols2keep = cols2keep)
kable(head(df.metval), caption = "BCGcalc metric.values")

```


# Other formatting options

# BCG level 1 signal

# 300 count model

# Exclude

----


